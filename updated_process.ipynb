{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from scipy.stats import spearmanr\n",
    "import seaborn as sns\n",
    "import re\n",
    "import itertools\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score, accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from plot import plot_confusion\n",
    "from plot import plot_cmap\n",
    "import numpy as np\n",
    "mpl.rcParams['font.sans-serif'] = ['Arial']\n",
    "mpl.rcParams['xtick.labelsize'] = 18\n",
    "mpl.rcParams['ytick.labelsize'] = 18\n",
    "mpl.rcParams.update({'font.size': 20})\n",
    "mpl.rcParams['font.sans-serif'] = ['Arial']\n",
    "mpl.rcParams['xtick.labelsize'] = 18\n",
    "mpl.rcParams['ytick.labelsize'] = 18\n",
    "mpl.rcParams.update({'font.size': 24})\n",
    "\n",
    "color = ['tab:blue', 'tab:green', 'tab:orange', 'tab:red', 'tab:olive', 'tab:purple',\n",
    "         'tab:cyan', 'tab:gray', 'tab:brown', 'black', 'darkgreen', 'deeppink']\n",
    "grid_color = ['tab:blue', 'tab:green', 'tab:orange', 'tab:red', 'tab:olive', 'tab:purple',\n",
    "         'tab:cyan', 'tab:gray', 'tab:brown', 'black', 'darkgreen', 'deeppink']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa258ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Main:\n",
    "    def __init__(self, input_file='mini project_v5.xlsx'):\n",
    "        self.input_file = input_file\n",
    "        self.formula = None\n",
    "        self.infor = None\n",
    "    def rand_jitter(arr):\n",
    "        np.random.seed(7)\n",
    "        if len(arr) == 0:\n",
    "            stdev = 0\n",
    "        else:\n",
    "            stdev = 0.04 * (max(arr) - min(arr))\n",
    "        jitter = arr + (np.random.randn(len(arr)) * stdev)\n",
    "        return jitter\n",
    "\n",
    "    def cal_rsq(x,y):\n",
    "        rsq = spearmanr(x, y)[0]\n",
    "        return rsq\n",
    "\n",
    "    def process(self):\n",
    "        self.formula = pd.read_excel(self.input_file, sheet_name='formula')\n",
    "        self.infor = pd.read_excel(self.input_file, sheet_name='infor')\n",
    "        self.formula.columns = self.formula.columns.str.strip()\n",
    "\n",
    "        mw_dict = dict(zip(self.infor['compound'], self.infor['MW']))\n",
    "        vabc_dict = dict(zip(self.infor['compound'], self.infor['Vabc']))\n",
    "        o_dict = dict(zip(self.infor['compound'], self.infor['O']))\n",
    "        f_dict = dict(zip(self.infor['compound'], self.infor['F']))\n",
    "        c_dict = dict(zip(self.infor['compound'], self.infor['C']))\n",
    "        h_dict = dict(zip(self.infor['compound'], self.infor['H']))\n",
    "        SLogP_dict = dict(zip(self.infor['compound'], self.infor['SLogP']))\n",
    "        cyclic_dict = dict(zip(self.infor['compound'], self.infor['cyclic']))\n",
    "\n",
    "        # Process formula data\n",
    "        for index, row in formula.iterrows():\n",
    "            formula_str = str(row['formula']).strip()\n",
    "            match = re.match(r\"([A-Za-z0-9\\-]+(?:-[A-Za-z0-9\\-]+)*)\\s*\\(([\\d\\.\\-]+(?:-[\\d\\.\\-]+)*)\\s*mol\\)\", formula_str)\n",
    "            if not match:\n",
    "                continue\n",
    "                \n",
    "            compounds_part, mols_part = match.groups()\n",
    "            compounds = compounds_part.split(\"-\")\n",
    "            compounds = [compound + \" \" for compound in compounds]\n",
    "            original_mols = [float(m) for m in mols_part.split(\"-\")]\n",
    "                \n",
    "            if len(compounds) != len(original_mols):\n",
    "                continue\n",
    "                    \n",
    "            # Tính tổng khối lượng của các hợp chất\n",
    "            total_mass = 0\n",
    "            for compound, mol in zip(compounds, original_mols):\n",
    "                for k in mw_dict.keys():\n",
    "                    if compound in k:\n",
    "                        total_mass += mw_dict[k] * mol if pd.notna(mw_dict[k]) else 0\n",
    "                        break\n",
    "            scale_factor = 100 / total_mass if total_mass > 0 else 0\n",
    "            for i, (compound, original_mols) in enumerate(zip(compounds, original_mols), start=1):\n",
    "                formula.loc[index, f\"c{i}\"] = compound\n",
    "                formula.loc[index, f\"n{i}\"] = original_mols * scale_factor\n",
    "        # tính số mol của Li và sol\n",
    "        for i in formula.index:\n",
    "            s_count = 1  \n",
    "            a_count = 1\n",
    "            Li = 0\n",
    "            sol = 0\n",
    "            \n",
    "            for j in range(1, 9):\n",
    "                c_col = f'c{j}'\n",
    "                n_col = f'n{j}'\n",
    "                if c_col in formula.columns and pd.notna(formula.loc[i, c_col]):\n",
    "                    compound = formula.loc[i, c_col]\n",
    "                    n_value = formula.loc[i, n_col]\n",
    "                    \n",
    "                    if 'Li' in compound:\n",
    "                        Li += n_value\n",
    "                        for k in o_dict.keys():\n",
    "                            if compound in k:\n",
    "                                formula.loc[i, f'a{a_count}O'] = o_dict[k] if pd.notna(o_dict[k]) else 0\n",
    "                                formula.loc[i, f'a{a_count}F'] = f_dict[k] if pd.notna(f_dict[k]) else 0\n",
    "                                a_count += 1\n",
    "                                break\n",
    "                    else:\n",
    "                        sol += n_value\n",
    "                        for k in o_dict.keys():\n",
    "                            if compound in k:\n",
    "                                formula.loc[i, f's{s_count}C'] = c_dict[k] if pd.notna(c_dict[k]) else 0\n",
    "                                formula.loc[i, f's{s_count}H'] = h_dict[k] if pd.notna(h_dict[k]) else 0\n",
    "                                formula.loc[i, f's{s_count}O'] = o_dict[k] if pd.notna(o_dict[k]) else 0\n",
    "                                formula.loc[i, f's{s_count}F'] = f_dict[k] if pd.notna(f_dict[k]) else 0\n",
    "                                s_count += 1\n",
    "                                break\n",
    "            \n",
    "            formula.loc[i, 'Li'] = Li\n",
    "            formula.loc[i, 'sol'] = sol\n",
    "            formula.loc[i, 'Li/sol'] = round(Li/sol, 3) if sol != 0 else 0\n",
    "        # tính tỉ lệ số mol của các nguyên tố\n",
    "        prefix_suffix_pairs = [\n",
    "            ('a', 'O'),\n",
    "            ('a', 'F'),\n",
    "            ('s', 'C'),\n",
    "            ('s', 'H'),\n",
    "            ('s', 'O'),\n",
    "            ('s', 'F'),\n",
    "            ('s', 'P'),\n",
    "            ('s', 'S')\n",
    "        ]\n",
    "\n",
    "        for prefix, suffix in prefix_suffix_pairs:\n",
    "            cols = [col for col in formula.columns if col.startswith(prefix) and col.endswith(suffix) and len(col) == 3]\n",
    "            formula[prefix + suffix] = formula[cols].sum(axis=1, skipna=True)\n",
    "\n",
    "        formula['sF/sC'] = formula.apply(lambda x: round(x['sF'] / x['sC'], 2) if pd.notna(x['sF']) and pd.notna(x['sC']) and x['sC'] != 0 else 0, axis=1)\n",
    "        formula['sF/sO'] = formula.apply(lambda x: round(x['sF'] / x['sO'], 2) if pd.notna(x['sF']) and pd.notna(x['sO']) and x['sO'] != 0 else 0, axis=1)\n",
    "        formula['sC.sH'] = formula.apply(lambda x: round(x['sC'] * x['sH'], 2) if pd.notna(x['sC']) and pd.notna(x['sH']) and x['sH'] != 0 else 0, axis=1)\n",
    "        formula['sO/sC'] = formula.apply(lambda x: round(x['sO'] / x['sC'], 2) if pd.notna(x['sO']) and pd.notna(x['sC']) and x['sC'] != 0 else 0, axis=1)\n",
    "        # tính số nối đôi O trong các hợp chất\n",
    "        smiles_dict = dict(zip(infor['compound'], infor['SMILES']))\n",
    "        formula['dbO'] = 0\n",
    "        for i in formula.index:\n",
    "            db_count = 0\n",
    "            for j in range(1, 9):\n",
    "                c_col = f'c{j}'\n",
    "                if c_col in formula.columns and pd.notna(formula.loc[i, c_col]):\n",
    "                    compound = formula.loc[i, c_col]\n",
    "                    for k in smiles_dict.keys():\n",
    "                        if compound in k and pd.notna(smiles_dict[k]):\n",
    "                            db_count += smiles_dict[k].count('=O')\n",
    "                            break\n",
    "            formula.loc[i, 'dbO'] = db_count\n",
    "        formula['sbO'] = formula['sO'] - formula['dbO']\n",
    "        # tính pct\n",
    "        for i in range(1, 9):\n",
    "            c_col = f'c{i}'\n",
    "            n_col = f'n{i}'\n",
    "            \n",
    "            if c_col in formula.columns:\n",
    "                pct_col = f'%n{i}'\n",
    "                formula[pct_col] = formula.apply(\n",
    "                    lambda row: round(row[n_col] / row['sol'] * 100, 2) if pd.notna(row[c_col]) and 'Li' not in str(row[c_col]) else np.nan,\n",
    "                    axis=1\n",
    "                )\n",
    "        # tính density\n",
    "        for i in formula.index:\n",
    "            total_mw = 0\n",
    "            total_vabc = 0\n",
    "            for j in range(1, 9):\n",
    "                c_col = f'c{j}'\n",
    "                n_col = f'n{j}'\n",
    "                if c_col in formula.columns and pd.notna(formula.loc[i, c_col]):\n",
    "                    compound = formula.loc[i, c_col]\n",
    "                    n_value = formula.loc[i, n_col]\n",
    "                    if 'Li' not in compound:\n",
    "                        for k in mw_dict.keys():\n",
    "                            if compound in k:\n",
    "                                total_mw += mw_dict[k] * n_value if pd.notna(mw_dict[k]) else 0\n",
    "                                total_vabc += vabc_dict[k] * n_value if pd.notna(vabc_dict[k]) else 0\n",
    "                                break\n",
    "            \n",
    "            formula.loc[i, 'density'] = round(total_mw/total_vabc, 3) if total_vabc != 0 else 0\n",
    "        # tính radius, apol, bpol, Vabc\n",
    "        properties = ['Radius', 'Vabc', 'apol', 'bpol']\n",
    "        property_dicts = {prop: dict(zip(infor['compound'], infor[prop])) for prop in properties}\n",
    "\n",
    "        for prop in properties:\n",
    "            formula[f'{prop}'] = formula[prop].astype(float)  \n",
    "            formula[f'{prop}-'] = formula[f'{prop}-'].astype(float)\n",
    "            formula[f'{prop}-r'] = formula[f'{prop}-r'].astype(float)\n",
    "            formula[f'{prop}+'] = formula[f'{prop}+'].astype(float)\n",
    "            formula[prop] = 0\n",
    "            formula[f'{prop}-'] = 1\n",
    "        for i in formula.index:\n",
    "            for prop in properties:\n",
    "                total_value = 0\n",
    "                minus_value = 1\n",
    "                for j in range(1, 9):\n",
    "                    c_col = f'c{j}'\n",
    "                    n_col = f'n{j}'\n",
    "                    pct_col = f'%n{j}'\n",
    "                    if c_col in formula.columns and pd.notna(formula.loc[i, c_col]):\n",
    "                        compound = formula.loc[i, c_col]\n",
    "                        n_value = formula.loc[i, n_col]\n",
    "                        n2_value = formula.loc[i, pct_col]\n",
    "                        if 'Li' not in compound:\n",
    "                            for k in property_dicts[prop].keys():\n",
    "                                if compound in k:\n",
    "                                    total_value += property_dicts[prop][k] * n_value if pd.notna(property_dicts[prop][k]) else 0\n",
    "                                    minus_value *= property_dicts[prop][k] ** n2_value if pd.notna(property_dicts[prop][k]) else 1\n",
    "                                    break\n",
    "                formula.loc[i, prop] = round(total_value, 3) if total_value != 0 else 0\n",
    "                formula[f'{prop}-'] = formula[f'{prop}-'].astype(float)\n",
    "                formula.loc[i, f'{prop}-'] = round(minus_value, 3) if minus_value != 1 else 1\n",
    "        for prop in properties:\n",
    "            formula[f'{prop}-r'] = formula.apply(lambda x: round(x[prop] / x['sol'], 3) if x['sol'] != 0 else 0, axis=1)\n",
    "            formula[f'{prop}+'] = formula.apply(lambda x: round((2 * x[f'{prop}-r']) - x[f'{prop}-'], 3), axis=1)\n",
    "        # tính SLogP\n",
    "        for i in formula.index:\n",
    "            total_slogp = 0\n",
    "            for j in range(1, 9):\n",
    "                c_col = f'c{j}'\n",
    "                pct_col = f'%n{j}'\n",
    "                if c_col in formula.columns and pd.notna(formula.loc[i, c_col]):\n",
    "                    compound = formula.loc[i, c_col]\n",
    "                    n2_value = formula.loc[i, pct_col]\n",
    "                    if 'Li' not in compound:\n",
    "                        for k in SLogP_dict.keys():\n",
    "                            if compound in k:\n",
    "                                if pd.notna(SLogP_dict[k]) and pd.notna(n2_value):\n",
    "                                    total_slogp += 10**SLogP_dict[k] * n2_value\n",
    "                                break\n",
    "                                \n",
    "            formula.loc[i, 'SLogP-r'] = round(np.log10(total_slogp), 3) if total_slogp > 0 else 0\n",
    "        # tính cyclic\n",
    "        for i in formula.index:\n",
    "            total_cyclic = 0\n",
    "            for j in range(1, 9):\n",
    "                c_col = f'c{j}'\n",
    "                n_col = f'n{j}'\n",
    "                if c_col in formula.columns and pd.notna(formula.loc[i, c_col]):\n",
    "                    compound = formula.loc[i, c_col]\n",
    "                    n_value = formula.loc[i, n_col]\n",
    "                    if 'Li' not in compound:\n",
    "                        for k in cyclic_dict.keys():\n",
    "                            if compound in k:\n",
    "                                total_cyclic += cyclic_dict[k] if pd.notna(cyclic_dict[k]) else 0\n",
    "                                break\n",
    "            formula.loc[i, 'cyclic'] = round(total_cyclic, 3) if total_cyclic != 0 else 0\n",
    "        # tính pi\n",
    "        formula['pi'] = 0\n",
    "        for i in formula.index:\n",
    "            pi_count = 0\n",
    "            for j in range(1, 9):\n",
    "                c_col = f'c{j}'\n",
    "                if c_col in formula.columns and pd.notna(formula.loc[i, c_col]):\n",
    "                    compound = formula.loc[i, c_col]\n",
    "                    if 'Li' not in compound:  # Only count for non-Li compounds\n",
    "                        for k in smiles_dict.keys():\n",
    "                            if compound in k and pd.notna(smiles_dict[k]):\n",
    "                                pi_count += smiles_dict[k].count('=')  # Count all double bonds\n",
    "                                break\n",
    "            formula.loc[i, 'pi'] = pi_count\n",
    "\n",
    "    def plot_results(self):\n",
    "        # Implement visualization using matplotlib and seaborn\n",
    "        pass\n",
    "\n",
    "    def regression(self):\n",
    "        features = ['Li', 'aF', 'aO', 'sC', 'sO', 'sF', 'pi', 'cyclic', 'apol', 'Vabc-', 'SLogP-r', 'Radius-r']\n",
    "        y = ['LCEi', 'LCEs', 'LCEs']\n",
    "        names = [cycle, cycle, aurbach]\n",
    "        tags = ['a)', 'd)', 'b)', 'e)', 'c)', 'f)']\n",
    "        split = 0.8\n",
    "        random_state = 7\n",
    "        #################################### Settings #################################### \n",
    "        fig, axs = plt.subplots(2,3, figsize=(28, 14), dpi = 192)\n",
    "        scaler = MinMaxScaler()\n",
    "        count=0\n",
    "\n",
    "        model_cycle = RandomForestRegressor(n_estimators=140,\n",
    "                                            max_depth=30,\n",
    "                                            criterion='absolute_error',\n",
    "                                            random_state=random_state)\n",
    "\n",
    "        model_aurbach = RandomForestRegressor(n_estimators=340,\n",
    "                                            max_depth=24,\n",
    "                                            criterion='absolute_error',\n",
    "                                            random_state=random_state)\n",
    "\n",
    "        models = [model_cycle, model_cycle, model_aurbach]\n",
    "\n",
    "        #################################### Running #################################### \n",
    "        for j in range(3):\n",
    "            file = names[j]\n",
    "            standardized_data = scaler.fit_transform(file[features])\n",
    "            df_std = pd.DataFrame(standardized_data, columns=file[features].columns)\n",
    "            X = df_std[features]\n",
    "            Y = file[y[j]]\n",
    "\n",
    "            x_train, x_test, y_train, y_test = train_test_split(X, Y, train_size = split, random_state=random_state)\n",
    "\n",
    "            # Train model\n",
    "            model = models[j].fit(x_train, y_train)\n",
    "            y_train_predict = model.predict(x_train)\n",
    "            y_test_predict = model.predict(x_test)\n",
    "            y_predict = model.predict(X)\n",
    "            \n",
    "            importances = model.feature_importances_\n",
    "            sorted_indices = np.argsort(importances)[::-1]\n",
    "\n",
    "            # Evaluate model:\n",
    "            rmse = root_mean_squared_error(Y, y_predict)\n",
    "            rsq = r2_score(Y, y_predict)\n",
    "                \n",
    "            # Create bar plot with viridis colormap\n",
    "            colors = plt.cm.viridis(np.linspace(0, 1, len(importances[sorted_indices])))\n",
    "            axs[0,j].bar(range(x_train.shape[1]), importances[sorted_indices], color=colors)\n",
    "\n",
    "            axs[0,j].set_ylabel(\"Relative importance\", fontsize=18)\n",
    "            #axs[0,j].set_ylabel(\"Mean decrease in impurity\", fontsize=18)\n",
    "            axs[0,j].set_xticks(range(x_train.shape[1]), x_train.columns[sorted_indices], rotation=0, fontsize=14)\n",
    "            axs[0,j].set_xticks(range(x_train.shape[1]), [features[i] for i in sorted_indices], rotation = 30)\n",
    "            axs[0,j].text(0.9, 0.95, tags[count], fontsize=26, c='black', verticalalignment='center', weight='bold', transform=axs[0,j].transAxes)\n",
    "\n",
    "            axs[1,j].scatter(y_train, y_train_predict, edgecolor='black', linewidth=1, s = 50, alpha = 0.6, c=\"#e84629\", label='train')\n",
    "            axs[1,j].scatter(y_test, y_test_predict, edgecolor='black', linewidth=1, s = 50, alpha = 0.7, c=\"darkcyan\", label='test')\n",
    "            axs[1,j].plot(Y, Y, c = 'black', linewidth = 2)\n",
    "            \n",
    "            axs[1,j].set_xlabel(f\"Observed {y[j]}\")\n",
    "            axs[1,j].set_ylabel(f\"Predicted {y[j]}\")\n",
    "            axs[1,j].legend(loc='lower right', )\n",
    "            axs[1,j].grid(color='black', linestyle='--', linewidth=1, alpha=0.2)\n",
    "            axs[1,j].spines[\"top\"].set_visible(False)\n",
    "            axs[1,j].spines[\"right\"].set_visible(False)\n",
    "            axs[1,j].spines[\"bottom\"].set_visible(False)\n",
    "            axs[1,j].spines[\"left\"].set_visible(False)\n",
    "            \n",
    "            axs[1,j].text(0.9, 1, tags[count+1], fontsize=26, c='black', verticalalignment='center', weight='bold', transform=axs[1,j].transAxes)\n",
    "            axs[1,j].text(0.05, 0.9, f'R$^2$: {round(rsq, 4)}', fontsize = 18, transform=axs[1,j].transAxes)\n",
    "            axs[1,j].text(0.05, 0.83, 'RMSE: {:0.3f}'.format(rmse), fontsize = 18, transform=axs[1,j].transAxes)\n",
    "            \n",
    "            count+=2\n",
    "            \n",
    "        axs[0,0].text(0.45, 0.95, 'Cycle', fontsize=32, c='darkgoldenrod', verticalalignment='center', transform=axs[0,0].transAxes)\n",
    "        axs[0,1].text(0.45, 0.95, 'Cycle', fontsize=32, c='darkgoldenrod', verticalalignment='center', transform=axs[0,1].transAxes)\n",
    "        axs[0,2].text(0.45, 0.95, 'Aurbach', fontsize=32, c='teal', verticalalignment='center', transform=axs[0,2].transAxes)\n",
    "        axs[1,2].set_xlabel(f\"Observed LCE\")\n",
    "        axs[1,2].set_ylabel(f\"Predicted LCE\")\n",
    "\n",
    "        #plt.savefig(f'Feature importance_{type(model_cycle).__name__}.tif', bbox_inches = 'tight')\n",
    "        plt.show()\n",
    "\n",
    "    def classification(self):\n",
    "        features = ['Li', 'aF', 'aO', 'sC', 'sO', 'sF', 'pi', 'cyclic', 'apol', 'Vabc-', 'SLogP-r', 'Radius-r']\n",
    "        y = 'class'\n",
    "        names = [cycle, aurbach]\n",
    "        colors = ['darkgoldenrod', 'teal']\n",
    "        titles = ['Cycle', 'Aurbach']\n",
    "        split = 0.8\n",
    "\n",
    "        #################################### Settings ####################################\n",
    "        fig, axs = plt.subplots(2,2,figsize=(10, 8), dpi = 192)\n",
    "        scaler = MinMaxScaler()\n",
    "\n",
    "        model_cycle = GradientBoostingClassifier(random_state=random_state,\n",
    "                                                learning_rate=0.1,\n",
    "                                                loss='exponential',\n",
    "                                                criterion='friedman_mse',\n",
    "                                                n_estimators=462,\n",
    "                                                max_depth=25,\n",
    "                                                min_samples_leaf=2,\n",
    "                                                min_samples_split=2)\n",
    "\n",
    "        model_aurbach = RandomForestClassifier(bootstrap=True,\n",
    "                                            criterion='gini',\n",
    "                                            max_features='sqrt',\n",
    "                                            min_samples_split=2,\n",
    "                                            min_samples_leaf=38,\n",
    "                                            max_depth=1,\n",
    "                                            n_estimators=28,\n",
    "                                            random_state=random_state)\n",
    "\n",
    "        #################################### Running ####################################\n",
    "        models = [model_cycle, model_aurbach]\n",
    "\n",
    "        for j in range(2):\n",
    "            file = names[j]\n",
    "            standardized_data = scaler.fit_transform(file[features])\n",
    "            df_std = pd.DataFrame(standardized_data, columns=file[features].columns)\n",
    "            X = df_std[features]\n",
    "            Y = file[y]\n",
    "            x_train, x_test, y_train, y_test = train_test_split(X, Y, train_size=split, \n",
    "                                                                random_state=random_state,\n",
    "                                                                stratify=Y)\n",
    "            \n",
    "            try:\n",
    "                clf = models[j].fit(x_train, y_train)\n",
    "                y_predict = clf.predict(X)\n",
    "            except ValueError as e:\n",
    "                print(f\"Error in {titles[j]} model: {str(e)}\")\n",
    "                print(f\"Class distribution in training set: {np.bincount(y_train)}\")\n",
    "                continue\n",
    "            accuracy = accuracy_score(Y, y_predict)\n",
    "            precision = precision_score(Y, y_predict)\n",
    "            recall = recall_score(Y, y_predict)\n",
    "            print('Accuracy: {:.03}% \\n'.format(accuracy*100))\n",
    "            \n",
    "            # Confusion matrix:\n",
    "            cnf_matrix = confusion_matrix(Y, y_predict)\n",
    "            cnf_matrix_norm = cnf_matrix.astype('float') / cnf_matrix.sum(axis=1, keepdims = True)\n",
    "            plot_confusion(Y, matrix=cnf_matrix, ax=axs[j,0], title = 'Confusion matrix', shrink=1)\n",
    "            plot_confusion(Y, matrix=cnf_matrix_norm, ax=axs[j,1], title = 'Normalized confusion matrix', rf = '.2f', shrink=1)\n",
    "\n",
    "            # Add text annotations\n",
    "            axs[j,0].text(1.65, 1.2, titles[j], fontsize=22, c=colors[j], verticalalignment='center', transform=axs[j,0].transAxes)\n",
    "            axs[j,0].text(1.5, 0.7, 'Precision: {:.03}% \\n'.format(precision*100), fontsize=15, c=colors[j], verticalalignment='center', transform=axs[j,0].transAxes)\n",
    "            axs[j,0].text(1.5, 0.55, 'Recall: {:.03}% \\n'.format(recall*100), fontsize=15, c=colors[j], verticalalignment='center', transform=axs[j,0].transAxes)\n",
    "\n",
    "            #save model in pkl file:\n",
    "            pkl_filename= f'{type(models[j]).__name__}_{titles[j]}.pkl'\n",
    "            with open(pkl_filename, 'wb') as file:  \n",
    "                pickle.dump(models[j], file)\n",
    "            with open(pkl_filename, 'rb') as file:  \n",
    "                saved_model = pickle.load(file)\n",
    "            print(saved_model)\n",
    "\n",
    "        fig.tight_layout()\n",
    "        #plt.savefig(f'Classification_performance.tif', bbox_inches = 'tight')\n",
    "        plt.show()\n",
    "\n",
    "    def run(self):\n",
    "        self.process()\n",
    "        self.plot_results()\n",
    "        self.regression()\n",
    "        self.classification()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main = Main()\n",
    "    main.run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
